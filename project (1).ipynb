{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMoRRwOsepqQhVxcg8CHDHf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Iw6mK4PoAxks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import necessary libraries\n","# # math opeations\n","\n","# # get latest version of pip\n","# !pip install --upgrade pip\n","\n","# # for calender map\n","# ! pip install calmap\n","\n","# # to convert us statenames to state codes\n","# ! pip install us\n","\n","# # to get continent name from country name\n","# ! pip install pycountry_convert\n","\n","# !pip install --upgrade plotly\n","\n","import math\n","# produce random numbers\n","import random\n","# to load json files\n","import json\n","# datetime oprations\n","from datetime import timedelta\n","# to get web contents\n","from urllib.request import urlopen\n","# for numerical analyiss\n","import numpy as np\n","# to store and process data in dataframe\n","import pandas as pd\n","# basic visualization package\n","import matplotlib.pyplot as plt\n","# advanced ploting\n","import seaborn as sns\n","\n","# interactive visualization\n","import plotly.express as px\n","import plotly.graph_objs as go\n","import plotly.figure_factory as ff\n","from plotly.subplots import make_subplots\n","# for offline ploting\n","from plotly.offline import plot, iplot, init_notebook_mode\n","init_notebook_mode(connected=True)\n","# converter\n","from pandas.plotting import register_matplotlib_converters\n","register_matplotlib_converters()\n","\n","# hide warnings\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","\n","# seaborn plot style\n","sns.set_style('darkgrid')\n","# Load the dataset\n","\n"],"metadata":{"id":"ig6-QvDABIGO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","full_table = pd.read_csv('/content/drive/MyDrive/Data Analytics and Visualization/Project/covid_19_clean_complete.csv')\n","# full_table.head()\n","\n","full_grouped = pd.read_csv('/content/drive/MyDrive/Data Analytics and Visualization/Project/full_grouped.csv')\n","full_grouped['Date'] = pd.to_datetime(full_grouped['Date'])\n","# full_grouped.head()\n","\n","\n","day_wise = pd.read_csv('/content/drive/MyDrive/Data Analytics and Visualization/Project/day_wise.csv')\n","day_wise['Date'] = pd.to_datetime(day_wise['Date'])\n","# day_wise.head()\n","\n","country_wise = pd.read_csv('/content/drive/MyDrive/Data Analytics and Visualization/Project/country_wise_latest.csv')\n","country_wise = country_wise.replace('', np.nan).fillna(0)\n","# country_wise.head()\n","\n","worldometer_data = pd.read_csv('/content/drive/MyDrive/Data Analytics and Visualization/Project/worldometer_data.csv')\n","worldometer_data = worldometer_data.replace('', np.nan).fillna(0)\n","# worldometer_data.head()\n","\n","data = pd.concat([worldometer_data,country_wise , day_wise ,full_grouped, full_table ])\n","\n","\n","\n"],"metadata":{"id":"OSbKEErsGSeZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(data.columns)\n","\n","# print(data.describe())\n","\n","# print(data.shape)"],"metadata":{"id":"Wy-YLUQUJGPX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Now we can handle these NaNs  by filling with mean.\n","full_table = full_table.fillna(full_table.mean())\n","# data = data.replace(,median)\n","\n","full_grouped = full_grouped.fillna(full_grouped.mean())\n","# data = data.replace(,median)\n","\n","day_wise = day_wise.fillna(day_wise.mean())\n","# data = data.replace(,median)\n","\n","country_wise = country_wise.fillna(country_wise.mean())\n","# data = data.replace(,median)\n","\n","worldometer_data = worldometer_data.fillna(worldometer_data.mean())\n","# data = data.replace(,median)\n","\n","\n","# Replace positive infinite values with a large number or the maximum of the non-infinite v\n","\n","full_grouped.replace([np.inf], np.nan, inplace=True)\n","\n","full_table.replace([np.inf], np.nan, inplace=True)\n","\n","day_wise.replace([np.inf], np.nan, inplace=True)\n","\n","worldometer_data.replace([np.inf], np.nan, inplace=True)\n","\n","country_wise.replace([np.inf], np.nan, inplace=True)\n","\n","\n","# Replace negative infinite values with a small number or the minimum of the non-infinite values in your data\n","\n","full_grouped.replace([-np.inf], np.nan, inplace=True)\n","\n","full_table.replace([-np.inf], np.nan, inplace=True)\n","\n","day_wise.replace([-np.inf], np.nan, inplace=True)\n","\n","worldometer_data.replace([-np.inf], np.nan, inplace=True)\n","\n","country_wise.replace([-np.inf], np.nan, inplace=True)\n","\n","# for column in full_grouped.columns:\n","#     if pd.api.types.is_datetime64_dtype(full_grouped[column]):\n","#         min_year = full_grouped[column].min().year\n","#         if min_year < 1:\n","#             full_grouped[column] = full_grouped[column].apply(lambda x: x.replace(year=x.year-min_year+1))\n","\n","# for column in full_table.columns:\n","#     if pd.api.types.is_datetime64_dtype(full_table[column]):\n","#         min_year = full_table[column].min().year\n","#         if min_year < 1:\n","#             full_table[column] = full_table[column].apply(lambda x: x.replace(year=x.year-min_year+1))\n","\n","# for column in day_wise.columns:\n","#     if pd.api.types.is_datetime64_dtype(day_wise[column]):\n","#         min_year = day_wise[column].min().year\n","#         if min_year < 1:\n","#             day_wise[column] = day_wise[column].apply(lambda x: x.replace(year=x.year-min_year+1))\n","\n","# for column in worldometer_data.columns:\n","#     if pd.api.types.is_datetime64_dtype(worldometer_data[column]):\n","#         min_year = worldometer_data[column].min().year\n","#         if min_year < 1:\n","#             worldometer_data[column] = worldometer_data[column].apply(lambda x: x.replace(year=x.year-min_year+1))\n","\n","# for column in country_wise.columns:\n","#     if pd.api.types.is_datetime64_dtype(country_wise[column]):\n","#         min_year = country_wise[column].min().year\n","#         if min_year < 1:\n","#             country_wise[column] = country_wise[column].apply(lambda x: x.replace(year=x.year-min_year+1))\n","\n","\n","\n","\n","data = pd.concat([worldometer_data,country_wise , day_wise ,full_grouped, full_table ])\n"],"metadata":{"id":"ya2vdRJ4LIGr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","\n","day_wise.hist(bins=15)\n","plt.title('Day_Wise')\n","\n","worldometer_data.hist(bins=15)\n","plt.title('Worldometer_data')\n","\n","full_table.hist(bins=15)\n","plt.title('Full_Table')\n","\n","full_grouped.hist(bins=15)\n","plt.title('Full_Groupd')\n","\n","country_wise.hist(bins=15)\n","plt.title('Country_Wise')\n"],"metadata":{"id":"DlfuAIUPOiZd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","country_wise.plot(kind='line')\n","plt.title('country_wise')\n","\n","full_table.plot(kind='line')\n","plt.title('full_table')\n","\n","worldometer_data.plot(kind='line')\n","plt.title('worldometer_data')\n","\n","\n","\n"],"metadata":{"id":"uA7I2ed-tlOt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","\n","plt.figure(figsize=(35, 15))  # Adjust to desired size\n","sns.heatmap(data.corr(), annot=True)\n","plt.show()\n"],"metadata":{"id":"b-PO8kQHSpi3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","data = data.sort_values('TotalDeaths', ascending=False)  # Sort by 'TotalDeaths'\n","top_n = 90  # Choose the top N countries\n","data_top_n = data.head(top_n)\n","\n","plt.figure(figsize=(22,30))\n","plt.barh(data_top_n['Country/Region'], data_top_n['TotalDeaths'])\n","plt.xlabel('Total Deaths')\n","plt.ylabel('Country/Region')\n","plt.title('Total Deaths by Country/Region')\n","plt.gca().invert_yaxis()  # Invert the y-axis to display the country with the most deaths at the top\n","plt.show()"],"metadata":{"id":"lVFDsat_gQ8F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","\n","# Load your dataset\n","# df = pd.read_csv('your_large_dataset.csv')\n","\n","# Select only the numerical columns\n","numerical_columns = ['Population', 'TotalCases', 'NewCases', 'TotalDeaths', 'NewDeaths', 'TotalRecovered', 'NewRecovered',\n","                     'ActiveCases', 'Serious,Critical', 'Tot Cases/1M pop', 'Deaths/1M pop', 'TotalTests', 'Tests/1M pop',\n","                     'Confirmed', 'Deaths', 'Recovered', 'Active', 'New cases', 'New deaths', 'New recovered',\n","                     'Deaths / 100 Cases', 'Recovered / 100 Cases', 'Deaths / 100 Recovered', 'Confirmed last week',\n","                     '1 week change', '1 week % increase', 'Lat', 'Long']\n","\n","data_numeric = data[numerical_columns]\n","\n","# Impute missing values with the mean\n","imputer = SimpleImputer(strategy='mean')\n","data_imputed = imputer.fit_transform(data_numeric)\n","\n","# Standardize the numerical data\n","scaler = StandardScaler()\n","X = scaler.fit_transform(data_imputed)\n","\n","# Perform clustering\n","kmeans = KMeans(n_clusters=3, random_state=42)\n","kmeans.fit(X)\n","\n","labels = kmeans.labels_\n"],"metadata":{"id":"xn12ls1lC8cE"},"execution_count":null,"outputs":[]}]}